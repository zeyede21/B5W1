{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d7210c-10e6-4186-9c54-6a7d64814a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwordcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NMF\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "# Load raw analyst ratings/news data\n",
    "news_df = pd.read_csv(\"/mnt/data/raw_analyst_ratings.csv\")\n",
    "\n",
    "# Clean column names\n",
    "news_df.columns = news_df.columns.str.strip().str.lower()\n",
    "\n",
    "# Parse date column\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce')\n",
    "\n",
    "# Headline length\n",
    "news_df['headline_length'] = news_df['headline'].astype(str).apply(len)\n",
    "\n",
    "# Publisher frequency\n",
    "publisher_counts = news_df['publisher'].value_counts()\n",
    "\n",
    "# Plot: Articles per publisher (Top 10)\n",
    "plt.figure(figsize=(10,6))\n",
    "publisher_counts.head(10).plot(kind='barh')\n",
    "plt.title(\"Top 10 Publishers by Article Count\")\n",
    "plt.xlabel(\"Number of Articles\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top_publishers.png\")\n",
    "\n",
    "# Plot: Article count over time\n",
    "articles_by_date = news_df.groupby(news_df['date'].dt.date).size()\n",
    "plt.figure(figsize=(14,6))\n",
    "articles_by_date.plot()\n",
    "plt.title(\"Articles Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"articles_over_time.png\")\n",
    "\n",
    "# Keyword extraction using TF-IDF + NMF Topic Modeling\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "x_tfidf = vectorizer.fit_transform(news_df['headline'].astype(str))\n",
    "n_topics = 5\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "nmf_features = nmf_model.fit_transform(x_tfidf)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(nmf_model.components_):\n",
    "    top_keywords = [feature_names[i] for i in topic.argsort()[-10:]]\n",
    "    print(f\"Topic #{topic_idx + 1}:\", \", \".join(top_keywords))\n",
    "\n",
    "# Save cleaned version for next step\n",
    "news_df.to_csv(\"/mnt/data/cleaned_news_data.csv\", index=False)\n",
    "\n",
    "# NEXT: Use technical indicators on TSLA/NVDA price data using TA-Lib  where should i run this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca32fd-a6ff-496b-ae10-522b31a86ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
